# Artificial Intelligence Notes  

> [!NOTE] 
> These are my personal notes and not an official assignment. They only reflect my study process for different tests throughout the course.  


These notes summarize concepts, problem-solving algorithms and perspectives I gathered throught the semester. 
They serve as a structured reference to understand fundamental AI topics to consolidate knowledge in a clear and practical way for future reference.  

# Index  
1. **Introduction to Artificial Intelligence**  
2. **Search Algorithms**

# Introduction to Artificial Intelligence 

## Conceptos generales

El campo de la IA se enfoca en el entendimiento y construcci√≥n de **entidades inteligentes**.

### Diferentes **niveles** de IA.

- Inteligencia d√©bil (soluciones de prop√≥sito espec√≠fico).
Estos sistemas son capaces de resolver problemas de un contexto o dominio espec√≠fico.
Estos se pueden combinar con otros sistemas para asemejar un nivel de inteligencia
mayor.

- Inteligencia general (soluciones humanas).
Este tipo de inteligencia es m√°s parecida a la inteligencia humana. En d√≥nde se es capaz
de aprender de experiencias previas para aplicarlas de un problema a otro.

- Superinteligencia (ficci√≥n).
M√°s cercano al tipo de inteligencia absoluta ilustrada mayormente en producci√≥n ficticias.

### Prueba de Alan Turing
En 1950 se propuso una prueba para responder a "¬øUna m√°quina puede pensar?‚Äù 

La prueba se basa en un interrogador humano realiza preguntas a dos individuos y al analizar respuestas no puede determinar si se trata de una m√°quina o no.

Capacidades de la m√°quina:
- Procesamiento de lenguaje natural. Saber comunicarse.
- Representaci√≥n de conocimiento. Saber retener lo que sabe o percibe.
- Razonamiento automatizado. Responder preguntas o determinar nuevas conclusiones.
- Aprendizaje autom√°tico. Adaptarse a nuevas circunstancias y extrapolar patrones.

La prueba total de Turing debe incluir adem√°s la capacidad de interact√∫ar con objetos y personas del mundo real:

- Visi√≥n computacional y reconocimiento de voz, para percibir el mundo.
- Rob√≥tica. Manipular y moverse.

> [!NOTE] 
> Estas capacidades componen gran parte de lo que es IA hasta la fecha actual.

### Qu√© problemas resuelve la IA?

Los algoritmos de IA no pueden resolver cualquier problema. Son parte de un contexto y un objetivo que se desea alcanzar. Apartir de esto se pueden
definir distintos paradigmas. 

----

- Problemas de b√∫squeda. Problemas con varias posibles soluciones.  
- Problemas optimizaci√≥n. Muchas soluciones v√°lidas pero la soluci√≥n √≥ptima es la m√°s dif√≠cil de encontrar.
- Problemas de predicci√≥n. Encontrar y usar patrones de datos para predecir comportamiento o estructura.
- Problemas de clasificaci√≥n. Encontrar patrones para clasificar conjuntos de datos.
- Problemas de clustering. Agrupaci√≥n de datos por similitud de atributos o elementos.

### Espacios de b√∫squeda. 
Es el conjunto de todos los posibles estados de un sistema. Mayormente por limitaciones computacionales, no siempre se pueden calcular todos los estados. 
- üîπTodos los posibles movimientos en un tablero de ajedrez o todos los posibles movimientos en un juego de gato.

### Algoritmos de b√∫squeda. 
Se eval√∫an futuros estados y se intenta encontrar la soluci√≥n √≥ptima al problema. Provee una forma inteligente de evaluar espacios de b√∫squeda.
- üîπ Utilizados en motores de b√∫squeda, aplicaciones de geolocalizaci√≥n y videojuegos.

### Algoritmos inspirados en biolog√≠a
Entre estos est√°n:
- Algoritmos evolutivos o gen√©ticos. Por ejemplo, las evoluciones en Flappy Bird con diferentes generaciones.
- Algoritmos ‚Äúswarm‚Äù. Por ejemplo, el algoritmo de enjambre de part√≠culas. Permite optimizar un problema a partir de soluciones
candidatas.

### Algoritmos de aprendizaje autom√°tico (Machine Learning)
Estos algoritmos hacen uso de un enfoque estad√≠stico para el procesamiento de datos. Estos
se pueden clasificar en:
- Aprendizaje supervisado.
- Aprendizaje no supervisado.
- Aprendizaje reforzado.

### Algoritmos de aprendizaje profundo (Deep Learning)
Este se deriva del aprendizaje autom√°tico. Son utilizados para alcanzar la inteligencia d√©bil y esforzarse por alcanzar la inteligencia general.
Enfocado en problemas de √°mbito general y de igual forma tiene enfoques de aprendizaje supervisado, no supervisado y reforzado.
Hace uso de varias capas de redes neuronales, cada capa funciona como un componente inteligente que resuelve un problema espec√≠fico/especializado.

### Algunas aplicaciones de la IA
- Detecci√≥n de fraude en sistemas bancarios.
- Ciberseguridad. Detecci√≥n de ataques potenciales a servidores, comportamiento inusual de transacciones, bloqueo de tr√°fico malicioso (DDoS), etc.
- Diagn√≥sticos m√©dicos.
- Telecomunicaciones.
- Agentes de IA en juegos.

## Historia de la IA
### Incepci√≥n de la IA (1943-1956)
Se propuso un modelo de ‚Äúneuronas artificiales‚Äù. Estas neuronas pod√≠an tener un espacio de encendido o apagado.

Se demostr√≥ que cualquier funci√≥n computable podr√≠a ser construida haciendo uso de neuronas interconectadas mediante conectivas l√≥gicas (AND, OR, NOT, etc.).

En 1950 se construy√≥ la primera red neuronal computacional (The SNARC).

En el art√≠culo Computing Machinery and Intelligence, Alan Turing introdujo el Turing Test, aprendizaje autom√°tico, algoritmos gen√©ticos y aprendizaje reforzado.

### La era del entusiasmo (1952-1969)
Se dieron hallazgos importantes en el campo de la IA, algunos de ellos son:
- General Problem Solver (GPS). Primer intento de imitar el raciocinio general humano.
- Geometry Theorem Prover. Programa capaz de probar teoremas matem√°ticos complejos.
- Juego de damas con IA. Primeros acercamientos de aprendizaje reforzado.
- Lenguaje de programaci√≥n LISP. Lenguaje de alto nivel que predomin√≥ el campo de IA durante los siguientes 30 a√±os.

### Sistemas expertos (1969-1986)
Los primeros a√±os de IA, la resoluci√≥n de problemas estaba basado en √°mbitos de prop√≥sito general. Estos m√©todos se llamaban m√©todos d√©biles debido a que, a pesar de ser generales, las soluciones no pueden escalar a instancias m√°s complejas o grandes del problema.

El enfoque pas√≥ completamente al dise√±o de sistemas expertos, en lugar de abarcar una amplia generalidad de problemas. Se enfocaron los sistemas en √°mbitos m√°s espec√≠ficos.

La idea principal era simular los conocimientos de los expertos en distintos √°mbitos (medicina, econom√≠a, etc.).

### Retorno de las redes neuronales (1986-Actualidad)
En la d√©cada de 1980, se redescubri√≥ el algoritmo de retro propagaci√≥n, aplicado a problemas de aprendizaje en ciencias de la computaci√≥n y psicolog√≠a.

Estos modelos ‚Äúconexionistas‚Äù fueron vistos como competidores de los enfoques simb√≥licos y l√≥gicos de la IA.

Los modelos de conexionistas ofrecen una forma m√°s fluida e imprecisa de procesar y desarrollar conceptos en el mundo real.

Los modelos de conexionistas tienen la capacidad de aprender de ejemplos y ajustar sus par√°metros para mejorar su rendimiento en futuros casos.

### Probabilidades y aprendizaje autom√°tico (1987-Actualidad)
La Inteligencia Artificial (IA) ha evolucionado de sistemas expertos fr√°giles a un enfoque basado en probabilidad y aprendizaje autom√°tico.

En 1988, se estableci√≥ una conexi√≥n importante entre la IA y otros campos, como la estad√≠stica y la teor√≠a de decisiones, a trav√©s de las redes bayesianas y el aprendizaje por refuerzo.

Se utilizan conjuntos de problemas de referencia para demostrar el progreso en IA. (Reconocimiento de im√°genes, traducci√≥n, etc.)

### Big Data (2001-Actualidad)
Los avances en la capacidad de c√≥mputo y la creaci√≥n de la World Wide Web han facilitado la creaci√≥n de grandes conjuntos de datos, conocidos como "big data".

Estos grandes conjuntos de datos, que incluyen textos, im√°genes, horas de voz y video, entre otros, han llevado al desarrollo de algoritmos de aprendizaje dise√±ados para aprovecharlos.

Aumentar el tama√±o del conjunto de datos puede ser m√°s beneficioso para mejorar el rendimiento del algoritmo que realizar peque√±os ajustes al mismo.

La disponibilidad de "big data" y el cambio hacia el aprendizaje autom√°tico ayudaron a que la IA recuperara su atractivo comercial.

### Aprendizaje profundo (2011-Actualidad)

El aprendizaje profundo se refiere a aprendizaje autom√°tico que utiliza m√∫ltiples capas de elementos de c√°lculo simples y ajustables.

La caracter√≠stica de ‚Äúprofundo‚Äù no es alusiva al nivel de ‚Äúcomprensi√≥n‚Äù de la m√°quina. Simplemente hace referencia a la cantidad de capas que utilice, siguiendo la idea de que, a mayor cantidad de capaz, esta estructura es m√°s profunda.

Los fundamentos del Deep Learning se dieron a conocer desde los a√±os 70‚Äôs pero su apogeo lleg√≥ hasta el 2011. Debido m√°s que todo a la evoluci√≥n del hardware y a la gran cantidad de datos a disposici√≥n.

## Representaciones del conocimiento

### Sistemas basados en reglas

Tambi√©n denominados sistemas expertos, fueron el primer atractivo comercial exitoso del √°rea de la Inteligencia Artificial.

IF (condici√≥n) THEN (acci√≥n)

Se usan reglas para guardar conocimientos.
Las reglas eran obtenidas por expertos en el respectivo campo.

### Redes sem√°nticas
Se enfoca en la relaci√≥n entre los objetos. Com√∫nmente representados como grafos dirigidos.

![Semantic Net](https://miro.medium.com/v2/resize:fit:549/1*nKuAX4Hbxzt45WZPIr8PSw.png)

### √Årboles de b√∫squeda
La IA gira entorno a algoritmos. Usualmente es pr√°ctico construir un algoritmo complejo con algoritmos m√°s sencillos que ayuden a alcanzar el objetivo principal.

### Redes neuronales artificiales (ANN)
Intenta simular las redes neuronales del cerebro humano.

Estas est√°n estructuradas con neuronas artificiales conectadas entre s√≠. Cada neurona puede recibir y mandar se√±ales a otras neuronas.

Estas neuronas pueden tener m√∫ltiples entradas y una sola salida.

## Agentes

Un agente es cualquier cosa que puede ser vista percibiendo su ambiente a trav√©s de sensores y realizando acciones en dicho ambiente mediante
actuadores.

Un ambiente puede ser cualquier lugar, es un espacio que definamos.

El t√©rmino percepci√≥n hace alusi√≥n al contenido que fue ‚Äúcaptado‚Äù por un agente a trav√©s de sus sensores. La secuencia perceptiva es el historial
de todo lo que el agente ha percibido.

Las acciones de un agente pueden depender de su conocimiento incorporado o de su secuencia perceptiva hasta el momento de realizada la acci√≥n.

El comportamiento de un agente est√° definido por su funci√≥n de agente, que asigna cada secuencia perceptiva a una determinada acci√≥n.

### Agente racional

Se debe evaluar el comportamiento de un agente mediante pruebas de rendimiento que eval√∫a cualquier secuencia de estados.

Las pruebas de rendimiento es m√°s efectivo basarse en lo que se desea lograr en el entorno en el que opera el agente, en lugar de centrarse 
en c√≥mo se supone que el agente debe comportarse.

Se deben construir agentes que reflejen cierta incertidumbre de forma inicial sobre el rendimiento ideal que deben alcanzar y que
lo aprendan a trav√©s del tiempo 

![AI Teaches Itself to Walk](https://cdn.80.lv/api/upload/content/49/64524e233f064.jpg)

Un agente racional es aquel que, para cada posible secuencia perceptiva, deber√° poder seleccionar una acci√≥n que se espera que maximice su rendimiento.

Estos agentes dependen de:
- Prueba de rendimiento define o mide la ‚Äúinteligencia‚Äù.
- Previo conocimiento del agente de su entorno.
- Acciones que puede realizar el agente.
- La secuencia perceptiva en tiempo real.

### Racionalidad vs. Omnisciencia
Un agente omnisciente es capaz de predecir la salida de sus acciones y actuar de acorde a ello.

Ser racional no significa ser perfecto. La racionalidad maximiza el rendimiento esperado, la perfecci√≥n maximiza
el rendimiento actual.

Un agente no debe ser dise√±ado de tal forma que pueda obtener informaci√≥n sin haberla captado previamente
(exceptuando su conocimiento base del mismo), un agente no debe ser omnisciente.

La obtenci√≥n de informaci√≥n es parte fundamental de la
racionalidad. Eso junto con el aprendizaje son capacidades
fundamentales de los agentes racionales.

Un agente puede tener un conocimiento base del
entorno, pero este puede ser modificado y/o aumentado.

### Autonom√≠a
Un agente que depende enteramente de su conocimiento previo, en lugar de su propia
percepci√≥n y aprendizaje es un agente que carece de autonom√≠a.

Inicialmente se espera que se tenga poca o nula experiencia, y que act√∫e de forma
aleatoria a no ser que sea ligeramente asistido.

Despu√©s de tener suficiente experiencia en su entorno, el comportamiento de un agente
racional puede volverse efectivamente independiente de su conocimiento previo.

## Entornos de trabajo

El entorno de trabajo, contexto o dominio espec√≠fico en el que un agente de IA realiza sus actividades o tareas. Es el entorno en el que el agente interact√∫a, percibe informaci√≥n, toma decisiones y realiza acciones para lograr un objetivo o resolver un problema.
Para dise√±ar un agente, primero se debe especificar el entorno de trabajo lo m√°s posible.

Este est√° compuesto de la siguiente forma (descripci√≥n PEAS):
- **P**rueba de rendimiento.
- **E**l ambiente.
- los **A**ctuadores.
- los **S**ensores.

### Propiedades de un entorno de trabajo
- Perceptibilidad (parcial o completa). Si los sensores tienen acceso de todo el estado del
ambiente en todo momento, entonces el entorno de trabajo es completamente
observable.

- Singularidad de agentes. Entorno con un solo agentes o con varios agentes.

- Naturaleza determin√≠stica. Si el siguiente estado est√° enteramente determinado por el
estado actual y por la acci√≥n realizada por el/los agentes, entonces se dice que el
ambiente es determinista.

- Temporalidad (secuencial o epis√≥dico). En un entorno de tarea epis√≥dico, la
experiencia se basa en episodios, cada episodio deriva una acci√≥n y estos son
independientes. En el caso secuencial, una acci√≥n podr√≠a afectar a las acciones futuras.

- Fluidez del entorno (est√°tico o din√°mico). ¬øEl entorno cambia a trav√©s del
tiempo/acciones?

- Fluidez del entorno (est√°tico o din√°mico). ¬øEl entorno cambia a trav√©s del
tiempo/acciones?

- Dimensionalidad del entorno (discreto o continuo). Se refiere a la naturaleza
dimensional del entorno en t√©rminos de estados, percepciones y acciones. Un entorno
discreto tiene un conjunto finito o contable de estados, percepciones y acciones,
mientras que un entorno continuo permite valores infinitos y variaciones en los estados,
percepciones y acciones.

- Ocultamiento del entorno (conocido o desconocido). Se refiere al grado de
conocimiento que el agente o dise√±ador tiene sobre el entorno en t√©rminos de sus leyes
o reglas fundamentales.

> [!TIP]
> Es posible que un ambiente sea conocido, pero a la vez parcialmente observable (juego de cartas, solitario). Y un ambiente desconocido puede ser completamente observable (ver en Google Maps el mapa de un lugar al que llegas por primera vez).

# Search Algorithms

## B√∫squeda en IA

### Introducci√≥n

No siempre es clara qu√© acci√≥n se debe tomar. Puede que sea necesario planificar considerando
una secuencia de acciones con el objetivo de llegar a alg√∫n estado objetivo/soluci√≥n.

Este proceso de denominado b√∫squeda, y este proceso de implementa en agentes resolventes
de problemas o agentes que resuelven problemas.

Para un agente siempre ser√° m√°s f√°cil fijarse en un objetivo, que considerar la infinidad de
opciones que ofrece su entorno para luego determinar dicho objetivo. Por lo que el agente debe:

1. Formularse un objetivo. (¬øQu√© acciones le permiten llegar al objetivo planeado?)

2. Formular el problema. (¬øQu√© acciones elegir?)

### Entorno

Hay una gran diferencia entre algoritmos informados, donde el agente es capaz de calcular y
estimar lo lejos que est√° del estado objetivo, y los algoritmos no informados, donde no est√°
disponible tal estimaci√≥n.

Si un agente tiene total informaci√≥n/visi√≥n del entorno, entonces este agente podr√° seguir los
siguientes pasos para la alcanzar la resoluci√≥n del problema:

1. Formulaci√≥n del objetivo.

2. Formulaci√≥n del problema.

3. B√∫squeda.

4. Ejecuci√≥n.

En un espacio completamente observable, determinista, entorno conocido la resoluci√≥n al
problema siempre ser√° una secuencia fija de acciones a realizar.

### Open-Closed Loop

En un espacio completamente observable, determinista, entorno conocido la resoluci√≥n al
problema siempre ser√° una secuencia fija de acciones a realizar.

Si dicho sistema es capaz de ignorar sus percepciones al seguir la secuencia de secuencias y de
igual forma alcanzar el objetivo planeado entonces se dice que es un sistema open-loop. No
existe posibilidad de que el sistema se equivoque, siempre se llegar√° a la soluci√≥n.

En caso contrario, un acercamiento closed-loop es cuando existe una posibilidad de que el
modelo se equivoque o que el ambiente sea no-determinista.

### Open-Closed Loop (Ejemplos)

Un filtrador de correos basura ‚Äúspam‚Äù es un
ejemplo de open-loop, este sistema no tomar√°
en cuenta correos anteriores que se hayan
clasificado como spam o ning√∫n otro factor.
Simplemente va a tomar la decisi√≥n basada en
las caracter√≠sticas b√°sicas del correo electr√≥nico.

Un ejemplo de closed-loop son los sistemas de
recomendaci√≥n personalizada de plataformas
streaming. Estos sistemas van a considerar en el
perfil y las preferencias. Adem√°s, de que estar√°
en constante aprendizaje.

### Problemas de b√∫squeda
Un problema de b√∫squeda se puede definir formalmente como:
- Un conjunto de posibles estados en el cual el entorno pueda estar. (Espacio de estados).
- El estado inicial de un agente.
- El conjunto de uno o varios estados objetivos.
- El conjunto de acciones que puede realizar el agente. En donde dependiendo del estado se determinar√° un conjunto finito de acciones a realizar por el agente.
- El modelo de transici√≥n, lo que describe lo que realiza cada acci√≥n. Resultado(Estado, Acci√≥n)
- Una funci√≥n de costo para cada acci√≥n. Donde se especifica el costo de realizar una acci√≥n a en un estado e para alcanzar alg√∫n estado e‚Äô. Costo(e, a, e‚Äô)

Una secuencia de acciones forma un camino (path), y una soluci√≥n es un camino desde el estado inicial hasta el estado objetivo.

El costo de un camino es simplemente la suma individual de los costos de las acciones individuales de dicho camino.

Una soluci√≥n √≥ptima es la soluci√≥n con menor coste entre todas las posibles soluciones.

## Algoritmos de b√∫squeda

Un algoritmo de b√∫squeda toma un problema de b√∫squeda como entrada y retorna una soluci√≥n, o una indicaci√≥n de fallo/error.

Se suelen usar grafos y √°rboles de b√∫squeda para representar estos algoritmos. Se forman varios caminos intentando encontrar
uno que llegue al estado objetivo.

La ra√≠z de estos √°rboles es el estado inicial.

No es lo mismo un √°rbol de b√∫squeda que un estado de espacios. El estado de espacios puede ser infinito, el √°rbol de b√∫squeda describe los caminos entre distintos estados para alcanzar el resultado.

### Best-first search

¬øC√≥mo saber que nodo expandir?

Un alcance general es el del algoritmo best-first search (BFS). En donde se elige el nodo n con el valor m√≠nimo de una funci√≥n de evaluaci√≥n f(n).

## Algoritmos de b√∫squeda No-informados

### Breadth-first search (BFS ~ no informado)

Los algoritmos de b√∫squeda no-informados se dan cuando no hay certeza sobre qu√© tan cerca se
est√° del objetivo principal.

El algoritmo Breadth-first search es apropiado cuando todas las acciones tienen el mismo costo. Quiere decir que no hay ‚Äúpreocupaci√≥n‚Äù sobre qu√© nodo expandir al momento de explorar el √°rbol de b√∫squeda.

### Algoritmo Dijkstra

Mientras que el algoritmo Breadth-first search va revisando una profundidad a la vez, este algoritmo va explorando seg√∫n el costo de cada nodo que va explorando.

### Depth-first search

Este algoritmo siempre expande el nodo m√°s profundo. Este no va a priorizar una soluci√≥n √≥ptima en t√©rminos de costo. Retorna la primera soluci√≥n que encuentra.

## Este algoritmo siempre expande el nodo m√°s profundo. Este no va a priorizar una soluci√≥n √≥ptima en t√©rminos de costo. Retorna la primera soluci√≥n que encuentra.

Las estrategias de b√∫squeda informada usan indicios espec√≠ficos del dominio para encontrar soluciones de manera m√°s eficiente que las estrategias no informadas.

Estos indicios se presentan en la forma de una funci√≥n heur√≠stica, denotada como h(n). h(n) representa el coste estimado del camino m√°s barato desde el estado en el nodo n hasta un estado objetivo.

### Algoritmos A*
El algoritmo A* (‚ÄúA estrella‚Äù) es una b√∫squeda best-first que usa una funci√≥n de evaluaci√≥n:

$$ f(n) = g(n) + h(n) $$

Donde \( g(n) \) es el costo del camino desde el estado inicial \( n \), y \( h(n) \) es el costo estimado del camino m√°s corto desde \( n \) hasta el estado objetivo.
